{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbaf7642",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Conv1D, Activation, Input,Flatten,Dense, GlobalMaxPooling1D, SpatialDropout1D, Add, Reshape, LeakyReLU, BatchNormalization, Lambda, GlobalAveragePooling1D\n",
    "from keras.regularizers import l2\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359cfb10",
   "metadata": {},
   "source": [
    "# Functions definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd6bf633",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(data, input_windows_size, labels_window_size, overlap_size):\n",
    "    input_windows = []\n",
    "    labels_windows = []\n",
    "    instance_tokens = data['instance_token'].unique()\n",
    "\n",
    "    for instance_token in instance_tokens:\n",
    "        instance_data = data[data['instance_token'] == instance_token][:]\n",
    "        # drop timestamp and instance_token columns\n",
    "        instance_data = instance_data.drop(columns=['timestamp', 'instance_token'])\n",
    "\n",
    "        # Create input windows\n",
    "        for i in range(0, len(instance_data) - input_windows_size - labels_window_size + 1, input_windows_size - overlap_size):\n",
    "            input_window = instance_data.iloc[i:i + input_windows_size][:].values\n",
    "            label_window = instance_data.iloc[i + input_windows_size:i + input_windows_size + labels_window_size][['x_rel', 'y_rel']].values\n",
    "            input_windows.append(input_window)\n",
    "            labels_windows.append(label_window)\n",
    "\n",
    "    return np.array(input_windows), np.array(labels_windows)\n",
    "\n",
    "def create_dataset_from_dir(data_dir, input_windows_size, labels_window_size, overlap_size):\n",
    "    data = pd.read_csv(os.path.join(data_dir, 'data.csv'))\n",
    "\n",
    "    # Create dataset\n",
    "    input_windows, labels_windows = create_dataset(data, input_windows_size, labels_window_size, overlap_size)\n",
    "    return input_windows, labels_windows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf5af23",
   "metadata": {},
   "source": [
    "# Dataset import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a01e6b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "root_dataset = os.path.join(cwd, 'processed_data', 'v1.0-trainval')\n",
    "train_dir = os.path.join(root_dataset, 'train')\n",
    "val_dir = os.path.join(root_dataset, 'val')\n",
    "test_dir = os.path.join(root_dataset, 'test')\n",
    "train_data = pd.read_csv(os.path.join(train_dir, 'data.csv'))\n",
    "val_data = pd.read_csv(os.path.join(val_dir, 'data.csv'))\n",
    "test_data = pd.read_csv(os.path.join(test_dir, 'data.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "420c93c4",
   "metadata": {},
   "source": [
    "Dataset is split into overlapping windows of 6 elements, with a label composed of the next 10 samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9dc18c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_windows_size = 10\n",
    "labels_window_size = 6\n",
    "overlap_size = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa80fba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape: (14463, 10, 11), (14463, 6, 2)\n",
      "Validation data shape: (3044, 10, 11), (3044, 6, 2)\n",
      "Test data shape: (3078, 10, 11), (3078, 6, 2)\n"
     ]
    }
   ],
   "source": [
    "# Create datasets\n",
    "x_train, y_train = create_dataset_from_dir(train_dir, input_windows_size, labels_window_size, overlap_size)\n",
    "x_val, y_val = create_dataset_from_dir(val_dir, input_windows_size, labels_window_size, overlap_size)\n",
    "x_test, y_test = create_dataset_from_dir(test_dir, input_windows_size, labels_window_size, overlap_size) \n",
    "\n",
    "print(f\"Train data shape: {x_train.shape}, {y_train.shape}\")\n",
    "print(f\"Validation data shape: {x_val.shape}, {y_val.shape}\")\n",
    "print(f\"Test data shape: {x_test.shape}, {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57213cd",
   "metadata": {},
   "source": [
    "# Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d14ffdeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tcn import TCN\n",
    "\n",
    "def create_tcn_seq2seq_model(input_shape,\n",
    "                             num_filters=32,\n",
    "                             kernel_size=3,\n",
    "                             num_dilations=2,\n",
    "                             dropout_rate=0.1,\n",
    "                             output_timesteps=6,\n",
    "                             output_features=2,\n",
    "                             alpha=0.1):\n",
    "    \"\"\"\n",
    "    Build a seq2seq forecaster using the keras-tcn library’s TCN layer.\n",
    "    \n",
    "    - input_shape: (history_length, num_input_features)\n",
    "    - TCN layer returns the last hidden state (return_sequences=False).\n",
    "    - A Dense+Reshape head produces exactly (output_timesteps, output_features).\n",
    "    \"\"\"\n",
    "    inputs = Input(shape=input_shape)   # e.g. (6, 5)\n",
    "    \n",
    "    # TCN encoder: returns a single vector summarizing the 6-step history\n",
    "    #   -- nb_filters: number of convolutional filters\n",
    "    #   -- kernel_size: width of the conv kernels\n",
    "    #   -- dilations: dilation factors for each residual block\n",
    "    #   -- dropout_rate: spatial dropout between conv layers\n",
    "    #   -- return_sequences=False to grab only the final step\n",
    "    tcn_out = TCN(\n",
    "        nb_filters=num_filters,\n",
    "        kernel_size=kernel_size,\n",
    "        dilations=[2 ** i for i in range(num_dilations)],\n",
    "        dropout_rate=dropout_rate,\n",
    "        return_sequences=True,\n",
    "        kernel_initializer='he_normal',\n",
    "        activation='linear',\n",
    "        use_batch_norm=True,\n",
    "    )(inputs)\n",
    "    \n",
    "    # Dense → reshape into the desired future horizon\n",
    "    x = GlobalAveragePooling1D()(tcn_out)  # summarizing while keeping temporal richness\n",
    "    x = Dense(output_timesteps * output_features, name='fc_future')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    outputs = Reshape((output_timesteps, output_features), name='reshape_future')(x)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=outputs, name='tcn_seq2seq_keras_tcn')\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b362dd",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "016cbd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = x_train.shape[1:]\n",
    "dropout_rate = 0.05\n",
    "use_skip_connections = True\n",
    "output_model_dir = os.path.join(cwd, 'output_model')\n",
    "if not os.path.exists(output_model_dir):\n",
    "    os.makedirs(output_model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b062e2e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tcn_seq2seq_keras_tcn\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 10, 11)]          0         \n",
      "                                                                 \n",
      " tcn_1 (TCN)                 (None, 10, 32)            11296     \n",
      "                                                                 \n",
      " global_average_pooling1d_1   (None, 32)               0         \n",
      " (GlobalAveragePooling1D)                                        \n",
      "                                                                 \n",
      " fc_future (Dense)           (None, 12)                396       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 12)               48        \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " reshape_future (Reshape)    (None, 6, 2)              0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,740\n",
      "Trainable params: 11,460\n",
      "Non-trainable params: 280\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_tcn_seq2seq_model(input_shape, dropout_rate=dropout_rate, output_timesteps=labels_window_size, output_features=2)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93fed3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = output_model_dir + \"\\model_trained\" + \".tf\"\n",
    "callbacks = keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=50,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.0001),\n",
    "    loss=\"mse\",\n",
    "    metrics=[\"mae\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a1125ac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5000\n",
      "57/57 [==============================] - 11s 18ms/step - loss: 0.9933 - mae: 0.7708 - val_loss: 1.7674 - val_mae: 0.7703\n",
      "Epoch 2/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.9715 - mae: 0.7484 - val_loss: 1.2418 - val_mae: 0.5026\n",
      "Epoch 3/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.9470 - mae: 0.7274 - val_loss: 1.6776 - val_mae: 0.4060\n",
      "Epoch 4/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.9224 - mae: 0.7170 - val_loss: 2.6249 - val_mae: 0.3908\n",
      "Epoch 5/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.9004 - mae: 0.7146 - val_loss: 3.8428 - val_mae: 0.4004\n",
      "Epoch 6/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.8866 - mae: 0.6944 - val_loss: 3.8162 - val_mae: 0.3792\n",
      "Epoch 7/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.8731 - mae: 0.6915 - val_loss: 3.3975 - val_mae: 0.3618\n",
      "Epoch 8/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.8602 - mae: 0.6868 - val_loss: 3.1146 - val_mae: 0.3411\n",
      "Epoch 9/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.8470 - mae: 0.6830 - val_loss: 3.1357 - val_mae: 0.3398\n",
      "Epoch 10/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.8351 - mae: 0.6814 - val_loss: 3.1403 - val_mae: 0.3357\n",
      "Epoch 11/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.8233 - mae: 0.6639 - val_loss: 2.9412 - val_mae: 0.3164\n",
      "Epoch 12/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.8101 - mae: 0.6693 - val_loss: 3.2691 - val_mae: 0.3094\n",
      "Epoch 13/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.7988 - mae: 0.6563 - val_loss: 3.5664 - val_mae: 0.3058\n",
      "Epoch 14/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.7882 - mae: 0.6392 - val_loss: 3.5940 - val_mae: 0.2863\n",
      "Epoch 15/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.7760 - mae: 0.6388 - val_loss: 4.0543 - val_mae: 0.2905\n",
      "Epoch 16/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.7651 - mae: 0.6319 - val_loss: 4.3097 - val_mae: 0.2889\n",
      "Epoch 17/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.7543 - mae: 0.6255 - val_loss: 4.8430 - val_mae: 0.2934\n",
      "Epoch 18/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.7433 - mae: 0.6214 - val_loss: 5.1095 - val_mae: 0.2973\n",
      "Epoch 19/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.7324 - mae: 0.6119 - val_loss: 5.0244 - val_mae: 0.2869\n",
      "Epoch 20/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.7227 - mae: 0.6076 - val_loss: 5.1504 - val_mae: 0.2889\n",
      "Epoch 21/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.7121 - mae: 0.6045 - val_loss: 5.8178 - val_mae: 0.2869\n",
      "Epoch 22/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.7021 - mae: 0.5996 - val_loss: 5.4477 - val_mae: 0.2831\n",
      "Epoch 23/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.6928 - mae: 0.5979 - val_loss: 5.8680 - val_mae: 0.2736\n",
      "Epoch 24/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.6841 - mae: 0.5847 - val_loss: 5.7258 - val_mae: 0.2768\n",
      "Epoch 25/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.6738 - mae: 0.5808 - val_loss: 5.1671 - val_mae: 0.2649\n",
      "Epoch 26/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.6646 - mae: 0.5769 - val_loss: 6.0272 - val_mae: 0.2663\n",
      "Epoch 27/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.6548 - mae: 0.5728 - val_loss: 6.4074 - val_mae: 0.2661\n",
      "Epoch 28/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.6455 - mae: 0.5713 - val_loss: 6.5463 - val_mae: 0.2620\n",
      "Epoch 29/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.6376 - mae: 0.5565 - val_loss: 5.3959 - val_mae: 0.2439\n",
      "Epoch 30/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.6281 - mae: 0.5600 - val_loss: 5.3006 - val_mae: 0.2469\n",
      "Epoch 31/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.6204 - mae: 0.5498 - val_loss: 5.3435 - val_mae: 0.2474\n",
      "Epoch 32/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.6113 - mae: 0.5459 - val_loss: 5.0989 - val_mae: 0.2411\n",
      "Epoch 33/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.6030 - mae: 0.5395 - val_loss: 4.6867 - val_mae: 0.2306\n",
      "Epoch 34/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.5937 - mae: 0.5362 - val_loss: 4.4765 - val_mae: 0.2302\n",
      "Epoch 35/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.5852 - mae: 0.5362 - val_loss: 4.1445 - val_mae: 0.2266\n",
      "Epoch 36/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.5760 - mae: 0.5353 - val_loss: 3.3835 - val_mae: 0.2171\n",
      "Epoch 37/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.5691 - mae: 0.5232 - val_loss: 3.3783 - val_mae: 0.2170\n",
      "Epoch 38/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.5609 - mae: 0.5209 - val_loss: 3.9922 - val_mae: 0.2215\n",
      "Epoch 39/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.5532 - mae: 0.5138 - val_loss: 4.2126 - val_mae: 0.2225\n",
      "Epoch 40/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.5450 - mae: 0.5112 - val_loss: 4.1935 - val_mae: 0.2207\n",
      "Epoch 41/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.5365 - mae: 0.5098 - val_loss: 3.5565 - val_mae: 0.2153\n",
      "Epoch 42/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.5295 - mae: 0.5049 - val_loss: 3.8214 - val_mae: 0.2133\n",
      "Epoch 43/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.5219 - mae: 0.4986 - val_loss: 3.6967 - val_mae: 0.2119\n",
      "Epoch 44/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.5133 - mae: 0.5003 - val_loss: 3.7403 - val_mae: 0.2123\n",
      "Epoch 45/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.5062 - mae: 0.4925 - val_loss: 3.0170 - val_mae: 0.2063\n",
      "Epoch 46/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.4981 - mae: 0.4932 - val_loss: 2.9380 - val_mae: 0.2040\n",
      "Epoch 47/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.4907 - mae: 0.4865 - val_loss: 3.0252 - val_mae: 0.2095\n",
      "Epoch 48/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.4827 - mae: 0.4884 - val_loss: 3.2035 - val_mae: 0.2121\n",
      "Epoch 49/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.4758 - mae: 0.4824 - val_loss: 2.9523 - val_mae: 0.2093\n",
      "Epoch 50/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.4676 - mae: 0.4824 - val_loss: 3.2526 - val_mae: 0.2094\n",
      "Epoch 51/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.4613 - mae: 0.4698 - val_loss: 3.3122 - val_mae: 0.2116\n",
      "Epoch 52/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.4536 - mae: 0.4703 - val_loss: 2.7501 - val_mae: 0.2084\n",
      "Epoch 53/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.4450 - mae: 0.4702 - val_loss: 2.8713 - val_mae: 0.2124\n",
      "Epoch 54/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.4378 - mae: 0.4653 - val_loss: 3.1423 - val_mae: 0.2170\n",
      "Epoch 55/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.4296 - mae: 0.4641 - val_loss: 2.4913 - val_mae: 0.2097\n",
      "Epoch 56/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.4208 - mae: 0.4608 - val_loss: 2.6957 - val_mae: 0.2165\n",
      "Epoch 57/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.4126 - mae: 0.4528 - val_loss: 2.2315 - val_mae: 0.2110\n",
      "Epoch 58/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.4019 - mae: 0.4525 - val_loss: 2.3841 - val_mae: 0.2074\n",
      "Epoch 59/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.3918 - mae: 0.4488 - val_loss: 2.1951 - val_mae: 0.2050\n",
      "Epoch 60/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.3828 - mae: 0.4412 - val_loss: 2.0809 - val_mae: 0.2002\n",
      "Epoch 61/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.3715 - mae: 0.4371 - val_loss: 1.9493 - val_mae: 0.1936\n",
      "Epoch 62/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.3615 - mae: 0.4291 - val_loss: 1.8652 - val_mae: 0.1912\n",
      "Epoch 63/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.3503 - mae: 0.4238 - val_loss: 2.0933 - val_mae: 0.1896\n",
      "Epoch 64/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.3416 - mae: 0.4139 - val_loss: 2.0003 - val_mae: 0.1849\n",
      "Epoch 65/5000\n",
      "57/57 [==============================] - 1s 12ms/step - loss: 0.3300 - mae: 0.4080 - val_loss: 1.8652 - val_mae: 0.1838\n",
      "Epoch 66/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.3187 - mae: 0.4029 - val_loss: 2.0960 - val_mae: 0.1842\n",
      "Epoch 67/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.3112 - mae: 0.3927 - val_loss: 1.5562 - val_mae: 0.1699\n",
      "Epoch 68/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.2988 - mae: 0.3900 - val_loss: 1.4668 - val_mae: 0.1684\n",
      "Epoch 69/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.2929 - mae: 0.3813 - val_loss: 1.4121 - val_mae: 0.1675\n",
      "Epoch 70/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.2829 - mae: 0.3752 - val_loss: 1.4246 - val_mae: 0.1680\n",
      "Epoch 71/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.2744 - mae: 0.3715 - val_loss: 1.3862 - val_mae: 0.1651\n",
      "Epoch 72/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.2676 - mae: 0.3650 - val_loss: 1.1171 - val_mae: 0.1625\n",
      "Epoch 73/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.2618 - mae: 0.3576 - val_loss: 1.3151 - val_mae: 0.1625\n",
      "Epoch 74/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.2504 - mae: 0.3568 - val_loss: 1.2040 - val_mae: 0.1641\n",
      "Epoch 75/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.2472 - mae: 0.3468 - val_loss: 1.1950 - val_mae: 0.1624\n",
      "Epoch 76/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.2394 - mae: 0.3437 - val_loss: 1.3955 - val_mae: 0.1659\n",
      "Epoch 77/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.2336 - mae: 0.3379 - val_loss: 1.2071 - val_mae: 0.1571\n",
      "Epoch 78/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.2288 - mae: 0.3310 - val_loss: 0.9756 - val_mae: 0.1494\n",
      "Epoch 79/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.2250 - mae: 0.3241 - val_loss: 0.9169 - val_mae: 0.1448\n",
      "Epoch 80/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.2141 - mae: 0.3248 - val_loss: 0.9813 - val_mae: 0.1507\n",
      "Epoch 81/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.2111 - mae: 0.3188 - val_loss: 1.1392 - val_mae: 0.1525\n",
      "Epoch 82/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.2061 - mae: 0.3126 - val_loss: 1.0101 - val_mae: 0.1493\n",
      "Epoch 83/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.1993 - mae: 0.3101 - val_loss: 1.1426 - val_mae: 0.1488\n",
      "Epoch 84/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.1968 - mae: 0.3016 - val_loss: 1.0721 - val_mae: 0.1479\n",
      "Epoch 85/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.1894 - mae: 0.3001 - val_loss: 1.0729 - val_mae: 0.1442\n",
      "Epoch 86/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.1864 - mae: 0.2954 - val_loss: 0.9384 - val_mae: 0.1413\n",
      "Epoch 87/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.1790 - mae: 0.2942 - val_loss: 0.6852 - val_mae: 0.1326\n",
      "Epoch 88/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.1787 - mae: 0.2876 - val_loss: 0.6422 - val_mae: 0.1311\n",
      "Epoch 89/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.1703 - mae: 0.2830 - val_loss: 0.6703 - val_mae: 0.1281\n",
      "Epoch 90/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.1717 - mae: 0.2750 - val_loss: 0.6623 - val_mae: 0.1232\n",
      "Epoch 91/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.1645 - mae: 0.2759 - val_loss: 0.8450 - val_mae: 0.1322\n",
      "Epoch 92/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.1601 - mae: 0.2736 - val_loss: 0.8667 - val_mae: 0.1333\n",
      "Epoch 93/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.1559 - mae: 0.2714 - val_loss: 0.9173 - val_mae: 0.1349\n",
      "Epoch 94/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.1544 - mae: 0.2646 - val_loss: 0.8082 - val_mae: 0.1285\n",
      "Epoch 95/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.1486 - mae: 0.2632 - val_loss: 0.9005 - val_mae: 0.1289\n",
      "Epoch 96/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.1471 - mae: 0.2565 - val_loss: 0.7822 - val_mae: 0.1250\n",
      "Epoch 97/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.1439 - mae: 0.2535 - val_loss: 0.6430 - val_mae: 0.1187\n",
      "Epoch 98/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.1395 - mae: 0.2503 - val_loss: 0.8256 - val_mae: 0.1206\n",
      "Epoch 99/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.1372 - mae: 0.2460 - val_loss: 0.7105 - val_mae: 0.1137\n",
      "Epoch 100/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.1346 - mae: 0.2429 - val_loss: 0.8008 - val_mae: 0.1168\n",
      "Epoch 101/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.1324 - mae: 0.2388 - val_loss: 0.6465 - val_mae: 0.1105\n",
      "Epoch 102/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.1260 - mae: 0.2376 - val_loss: 0.6616 - val_mae: 0.1095\n",
      "Epoch 103/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.1220 - mae: 0.2345 - val_loss: 0.8052 - val_mae: 0.1129\n",
      "Epoch 104/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.1226 - mae: 0.2315 - val_loss: 0.7672 - val_mae: 0.1109\n",
      "Epoch 105/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.1192 - mae: 0.2272 - val_loss: 0.7344 - val_mae: 0.1085\n",
      "Epoch 106/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.1160 - mae: 0.2232 - val_loss: 0.4886 - val_mae: 0.1035\n",
      "Epoch 107/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.1123 - mae: 0.2204 - val_loss: 0.5076 - val_mae: 0.1013\n",
      "Epoch 108/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.1082 - mae: 0.2170 - val_loss: 0.4775 - val_mae: 0.0978\n",
      "Epoch 109/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.1066 - mae: 0.2129 - val_loss: 0.6207 - val_mae: 0.1019\n",
      "Epoch 110/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.1023 - mae: 0.2106 - val_loss: 0.3626 - val_mae: 0.0950\n",
      "Epoch 111/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.0990 - mae: 0.2086 - val_loss: 0.2631 - val_mae: 0.0895\n",
      "Epoch 112/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.0986 - mae: 0.2005 - val_loss: 0.2996 - val_mae: 0.0861\n",
      "Epoch 113/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.0928 - mae: 0.2014 - val_loss: 0.3556 - val_mae: 0.0885\n",
      "Epoch 114/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.0935 - mae: 0.1952 - val_loss: 0.3560 - val_mae: 0.0848\n",
      "Epoch 115/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.0901 - mae: 0.1926 - val_loss: 0.4463 - val_mae: 0.0862\n",
      "Epoch 116/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.0856 - mae: 0.1908 - val_loss: 0.3426 - val_mae: 0.0825\n",
      "Epoch 117/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.0850 - mae: 0.1851 - val_loss: 0.2822 - val_mae: 0.0772\n",
      "Epoch 118/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.0836 - mae: 0.1813 - val_loss: 0.2611 - val_mae: 0.0735\n",
      "Epoch 119/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.0805 - mae: 0.1800 - val_loss: 0.3767 - val_mae: 0.0789\n",
      "Epoch 120/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.0787 - mae: 0.1765 - val_loss: 0.3205 - val_mae: 0.0731\n",
      "Epoch 121/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.0764 - mae: 0.1740 - val_loss: 0.4074 - val_mae: 0.0738\n",
      "Epoch 122/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.0721 - mae: 0.1719 - val_loss: 0.3832 - val_mae: 0.0743\n",
      "Epoch 123/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.0718 - mae: 0.1666 - val_loss: 0.3203 - val_mae: 0.0723\n",
      "Epoch 124/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.0702 - mae: 0.1634 - val_loss: 0.3280 - val_mae: 0.0668\n",
      "Epoch 125/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.0677 - mae: 0.1617 - val_loss: 0.4631 - val_mae: 0.0719\n",
      "Epoch 126/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.0675 - mae: 0.1584 - val_loss: 0.3062 - val_mae: 0.0674\n",
      "Epoch 127/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.0642 - mae: 0.1540 - val_loss: 0.1626 - val_mae: 0.0588\n",
      "Epoch 128/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.0597 - mae: 0.1545 - val_loss: 0.2135 - val_mae: 0.0626\n",
      "Epoch 129/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.0604 - mae: 0.1494 - val_loss: 0.2008 - val_mae: 0.0568\n",
      "Epoch 130/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.0597 - mae: 0.1473 - val_loss: 0.1715 - val_mae: 0.0557\n",
      "Epoch 131/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.0586 - mae: 0.1443 - val_loss: 0.2456 - val_mae: 0.0567\n",
      "Epoch 132/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.0560 - mae: 0.1432 - val_loss: 0.1938 - val_mae: 0.0557\n",
      "Epoch 133/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.0526 - mae: 0.1412 - val_loss: 0.2464 - val_mae: 0.0571\n",
      "Epoch 134/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.0535 - mae: 0.1385 - val_loss: 0.2728 - val_mae: 0.0546\n",
      "Epoch 135/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.0496 - mae: 0.1382 - val_loss: 0.1978 - val_mae: 0.0513\n",
      "Epoch 136/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.0485 - mae: 0.1348 - val_loss: 0.1772 - val_mae: 0.0508\n",
      "Epoch 137/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.0496 - mae: 0.1323 - val_loss: 0.1571 - val_mae: 0.0491\n",
      "Epoch 138/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.0469 - mae: 0.1300 - val_loss: 0.2192 - val_mae: 0.0505\n",
      "Epoch 139/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.0454 - mae: 0.1282 - val_loss: 0.1777 - val_mae: 0.0490\n",
      "Epoch 140/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.0456 - mae: 0.1258 - val_loss: 0.1661 - val_mae: 0.0479\n",
      "Epoch 141/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.0449 - mae: 0.1239 - val_loss: 0.1444 - val_mae: 0.0456\n",
      "Epoch 142/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.0447 - mae: 0.1221 - val_loss: 0.1522 - val_mae: 0.0466\n",
      "Epoch 143/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.0432 - mae: 0.1201 - val_loss: 0.1612 - val_mae: 0.0462\n",
      "Epoch 144/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.0407 - mae: 0.1189 - val_loss: 0.1217 - val_mae: 0.0435\n",
      "Epoch 145/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.0397 - mae: 0.1172 - val_loss: 0.1920 - val_mae: 0.0468\n",
      "Epoch 146/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.0373 - mae: 0.1152 - val_loss: 0.1508 - val_mae: 0.0454\n",
      "Epoch 147/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.0388 - mae: 0.1132 - val_loss: 0.1247 - val_mae: 0.0434\n",
      "Epoch 148/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.0364 - mae: 0.1123 - val_loss: 0.1449 - val_mae: 0.0437\n",
      "Epoch 149/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.0353 - mae: 0.1107 - val_loss: 0.1285 - val_mae: 0.0417\n",
      "Epoch 150/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.0352 - mae: 0.1087 - val_loss: 0.1430 - val_mae: 0.0418\n",
      "Epoch 151/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.0356 - mae: 0.1067 - val_loss: 0.1091 - val_mae: 0.0408\n",
      "Epoch 152/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.0333 - mae: 0.1053 - val_loss: 0.0621 - val_mae: 0.0360\n",
      "Epoch 153/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.0324 - mae: 0.1044 - val_loss: 0.0928 - val_mae: 0.0368\n",
      "Epoch 154/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.0318 - mae: 0.1032 - val_loss: 0.0585 - val_mae: 0.0355\n",
      "Epoch 155/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.0303 - mae: 0.1016 - val_loss: 0.0798 - val_mae: 0.0380\n",
      "Epoch 156/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.0304 - mae: 0.0994 - val_loss: 0.1269 - val_mae: 0.0391\n",
      "Epoch 157/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.0294 - mae: 0.0986 - val_loss: 0.1297 - val_mae: 0.0396\n",
      "Epoch 158/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.0286 - mae: 0.0974 - val_loss: 0.0716 - val_mae: 0.0377\n",
      "Epoch 159/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.0262 - mae: 0.0962 - val_loss: 0.0912 - val_mae: 0.0380\n",
      "Epoch 160/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.0277 - mae: 0.0945 - val_loss: 0.0811 - val_mae: 0.0387\n",
      "Epoch 161/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.0257 - mae: 0.0937 - val_loss: 0.0902 - val_mae: 0.0370\n",
      "Epoch 162/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.0262 - mae: 0.0922 - val_loss: 0.1142 - val_mae: 0.0381\n",
      "Epoch 163/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.0258 - mae: 0.0904 - val_loss: 0.0996 - val_mae: 0.0375\n",
      "Epoch 164/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.0243 - mae: 0.0898 - val_loss: 0.1137 - val_mae: 0.0382\n",
      "Epoch 165/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.0236 - mae: 0.0880 - val_loss: 0.0945 - val_mae: 0.0370\n",
      "Epoch 166/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.0225 - mae: 0.0870 - val_loss: 0.1146 - val_mae: 0.0374\n",
      "Epoch 167/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.0232 - mae: 0.0859 - val_loss: 0.0876 - val_mae: 0.0359\n",
      "Epoch 168/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.0215 - mae: 0.0848 - val_loss: 0.0900 - val_mae: 0.0357\n",
      "Epoch 169/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.0232 - mae: 0.0826 - val_loss: 0.0622 - val_mae: 0.0335\n",
      "Epoch 170/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.0222 - mae: 0.0815 - val_loss: 0.0626 - val_mae: 0.0329\n",
      "Epoch 171/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.0201 - mae: 0.0810 - val_loss: 0.0843 - val_mae: 0.0346\n",
      "Epoch 172/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.0199 - mae: 0.0799 - val_loss: 0.1111 - val_mae: 0.0345\n",
      "Epoch 173/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.0181 - mae: 0.0792 - val_loss: 0.0701 - val_mae: 0.0338\n",
      "Epoch 174/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.0182 - mae: 0.0774 - val_loss: 0.0646 - val_mae: 0.0337\n",
      "Epoch 175/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.0181 - mae: 0.0763 - val_loss: 0.0915 - val_mae: 0.0335\n",
      "Epoch 176/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.0168 - mae: 0.0755 - val_loss: 0.0881 - val_mae: 0.0335\n",
      "Epoch 177/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.0167 - mae: 0.0738 - val_loss: 0.0717 - val_mae: 0.0340\n",
      "Epoch 178/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.0168 - mae: 0.0733 - val_loss: 0.0712 - val_mae: 0.0336\n",
      "Epoch 179/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.0161 - mae: 0.0722 - val_loss: 0.0916 - val_mae: 0.0328\n",
      "Epoch 180/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.0157 - mae: 0.0707 - val_loss: 0.0705 - val_mae: 0.0321\n",
      "Epoch 181/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.0155 - mae: 0.0700 - val_loss: 0.0672 - val_mae: 0.0322\n",
      "Epoch 182/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.0158 - mae: 0.0686 - val_loss: 0.0684 - val_mae: 0.0316\n",
      "Epoch 183/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.0150 - mae: 0.0673 - val_loss: 0.0561 - val_mae: 0.0305\n",
      "Epoch 184/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.0141 - mae: 0.0672 - val_loss: 0.0904 - val_mae: 0.0321\n",
      "Epoch 185/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.0133 - mae: 0.0659 - val_loss: 0.0832 - val_mae: 0.0321\n",
      "Epoch 186/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.0138 - mae: 0.0652 - val_loss: 0.0592 - val_mae: 0.0308\n",
      "Epoch 187/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.0136 - mae: 0.0637 - val_loss: 0.0557 - val_mae: 0.0304\n",
      "Epoch 188/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.0128 - mae: 0.0634 - val_loss: 0.0559 - val_mae: 0.0310\n",
      "Epoch 189/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.0126 - mae: 0.0624 - val_loss: 0.0771 - val_mae: 0.0316\n",
      "Epoch 190/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.0119 - mae: 0.0611 - val_loss: 0.0537 - val_mae: 0.0296\n",
      "Epoch 191/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.0111 - mae: 0.0601 - val_loss: 0.0531 - val_mae: 0.0299\n",
      "Epoch 192/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.0106 - mae: 0.0594 - val_loss: 0.0511 - val_mae: 0.0301\n",
      "Epoch 193/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.0111 - mae: 0.0585 - val_loss: 0.0550 - val_mae: 0.0300\n",
      "Epoch 194/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.0106 - mae: 0.0576 - val_loss: 0.0677 - val_mae: 0.0306\n",
      "Epoch 195/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.0099 - mae: 0.0564 - val_loss: 0.0440 - val_mae: 0.0295\n",
      "Epoch 196/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.0107 - mae: 0.0557 - val_loss: 0.0469 - val_mae: 0.0297\n",
      "Epoch 197/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.0101 - mae: 0.0552 - val_loss: 0.0505 - val_mae: 0.0292\n",
      "Epoch 198/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.0096 - mae: 0.0536 - val_loss: 0.0592 - val_mae: 0.0294\n",
      "Epoch 199/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.0097 - mae: 0.0533 - val_loss: 0.0497 - val_mae: 0.0289\n",
      "Epoch 200/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.0087 - mae: 0.0520 - val_loss: 0.0496 - val_mae: 0.0290\n",
      "Epoch 201/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.0087 - mae: 0.0513 - val_loss: 0.0567 - val_mae: 0.0289\n",
      "Epoch 202/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.0083 - mae: 0.0506 - val_loss: 0.0442 - val_mae: 0.0285\n",
      "Epoch 203/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.0080 - mae: 0.0501 - val_loss: 0.0495 - val_mae: 0.0284\n",
      "Epoch 204/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.0084 - mae: 0.0489 - val_loss: 0.0531 - val_mae: 0.0282\n",
      "Epoch 205/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.0077 - mae: 0.0485 - val_loss: 0.0523 - val_mae: 0.0286\n",
      "Epoch 206/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.0073 - mae: 0.0476 - val_loss: 0.0465 - val_mae: 0.0281\n",
      "Epoch 207/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.0077 - mae: 0.0468 - val_loss: 0.0470 - val_mae: 0.0283\n",
      "Epoch 208/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.0074 - mae: 0.0463 - val_loss: 0.0462 - val_mae: 0.0283\n",
      "Epoch 209/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.0068 - mae: 0.0459 - val_loss: 0.0327 - val_mae: 0.0280\n",
      "Epoch 210/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.0068 - mae: 0.0450 - val_loss: 0.0338 - val_mae: 0.0273\n",
      "Epoch 211/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.0057 - mae: 0.0441 - val_loss: 0.0527 - val_mae: 0.0286\n",
      "Epoch 212/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.0066 - mae: 0.0431 - val_loss: 0.0403 - val_mae: 0.0274\n",
      "Epoch 213/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.0059 - mae: 0.0430 - val_loss: 0.0445 - val_mae: 0.0277\n",
      "Epoch 214/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.0055 - mae: 0.0420 - val_loss: 0.0414 - val_mae: 0.0279\n",
      "Epoch 215/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.0054 - mae: 0.0416 - val_loss: 0.0380 - val_mae: 0.0276\n",
      "Epoch 216/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.0052 - mae: 0.0410 - val_loss: 0.0342 - val_mae: 0.0277\n",
      "Epoch 217/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.0058 - mae: 0.0407 - val_loss: 0.0379 - val_mae: 0.0276\n",
      "Epoch 218/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.0051 - mae: 0.0402 - val_loss: 0.0353 - val_mae: 0.0273\n",
      "Epoch 219/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.0051 - mae: 0.0393 - val_loss: 0.0403 - val_mae: 0.0280\n",
      "Epoch 220/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.0050 - mae: 0.0387 - val_loss: 0.0336 - val_mae: 0.0274\n",
      "Epoch 221/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.0050 - mae: 0.0383 - val_loss: 0.0337 - val_mae: 0.0273\n",
      "Epoch 222/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.0046 - mae: 0.0374 - val_loss: 0.0412 - val_mae: 0.0273\n",
      "Epoch 223/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.0044 - mae: 0.0370 - val_loss: 0.0431 - val_mae: 0.0276\n",
      "Epoch 224/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.0044 - mae: 0.0365 - val_loss: 0.0361 - val_mae: 0.0267\n",
      "Epoch 225/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.0041 - mae: 0.0362 - val_loss: 0.0415 - val_mae: 0.0272\n",
      "Epoch 226/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.0041 - mae: 0.0358 - val_loss: 0.0345 - val_mae: 0.0271\n",
      "Epoch 227/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.0041 - mae: 0.0351 - val_loss: 0.0429 - val_mae: 0.0275\n",
      "Epoch 228/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.0040 - mae: 0.0347 - val_loss: 0.0360 - val_mae: 0.0273\n",
      "Epoch 229/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.0038 - mae: 0.0346 - val_loss: 0.0427 - val_mae: 0.0275\n",
      "Epoch 230/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.0037 - mae: 0.0339 - val_loss: 0.0312 - val_mae: 0.0270\n",
      "Epoch 231/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.0038 - mae: 0.0336 - val_loss: 0.0301 - val_mae: 0.0266\n",
      "Epoch 232/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.0036 - mae: 0.0336 - val_loss: 0.0292 - val_mae: 0.0269\n",
      "Epoch 233/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.0036 - mae: 0.0333 - val_loss: 0.0288 - val_mae: 0.0268\n",
      "Epoch 234/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.0033 - mae: 0.0328 - val_loss: 0.0259 - val_mae: 0.0270\n",
      "Epoch 235/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.0033 - mae: 0.0322 - val_loss: 0.0305 - val_mae: 0.0271\n",
      "Epoch 236/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.0030 - mae: 0.0318 - val_loss: 0.0308 - val_mae: 0.0269\n",
      "Epoch 237/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.0032 - mae: 0.0312 - val_loss: 0.0283 - val_mae: 0.0270\n",
      "Epoch 238/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.0029 - mae: 0.0310 - val_loss: 0.0269 - val_mae: 0.0270\n",
      "Epoch 239/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.0028 - mae: 0.0305 - val_loss: 0.0332 - val_mae: 0.0272\n",
      "Epoch 240/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.0027 - mae: 0.0302 - val_loss: 0.0288 - val_mae: 0.0267\n",
      "Epoch 241/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.0027 - mae: 0.0300 - val_loss: 0.0293 - val_mae: 0.0267\n",
      "Epoch 242/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.0027 - mae: 0.0296 - val_loss: 0.0265 - val_mae: 0.0267\n",
      "Epoch 243/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.0028 - mae: 0.0295 - val_loss: 0.0258 - val_mae: 0.0264\n",
      "Epoch 244/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.0026 - mae: 0.0288 - val_loss: 0.0246 - val_mae: 0.0264\n",
      "Epoch 245/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.0025 - mae: 0.0287 - val_loss: 0.0245 - val_mae: 0.0263\n",
      "Epoch 246/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.0024 - mae: 0.0285 - val_loss: 0.0234 - val_mae: 0.0263\n",
      "Epoch 247/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.0022 - mae: 0.0284 - val_loss: 0.0235 - val_mae: 0.0263\n",
      "Epoch 248/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.0023 - mae: 0.0279 - val_loss: 0.0213 - val_mae: 0.0261\n",
      "Epoch 249/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.0024 - mae: 0.0275 - val_loss: 0.0262 - val_mae: 0.0266\n",
      "Epoch 250/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.0023 - mae: 0.0273 - val_loss: 0.0244 - val_mae: 0.0262\n",
      "Epoch 251/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.0021 - mae: 0.0269 - val_loss: 0.0222 - val_mae: 0.0263\n",
      "Epoch 252/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.0020 - mae: 0.0263 - val_loss: 0.0180 - val_mae: 0.0259\n",
      "Epoch 253/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.0020 - mae: 0.0260 - val_loss: 0.0192 - val_mae: 0.0258\n",
      "Epoch 254/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.0020 - mae: 0.0263 - val_loss: 0.0227 - val_mae: 0.0262\n",
      "Epoch 255/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.0021 - mae: 0.0260 - val_loss: 0.0223 - val_mae: 0.0263\n",
      "Epoch 256/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.0020 - mae: 0.0258 - val_loss: 0.0203 - val_mae: 0.0262\n",
      "Epoch 257/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.0019 - mae: 0.0257 - val_loss: 0.0168 - val_mae: 0.0258\n",
      "Epoch 258/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.0020 - mae: 0.0255 - val_loss: 0.0204 - val_mae: 0.0260\n",
      "Epoch 259/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.0017 - mae: 0.0248 - val_loss: 0.0219 - val_mae: 0.0261\n",
      "Epoch 260/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.0018 - mae: 0.0248 - val_loss: 0.0184 - val_mae: 0.0259\n",
      "Epoch 261/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.0017 - mae: 0.0243 - val_loss: 0.0197 - val_mae: 0.0260\n",
      "Epoch 262/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.0018 - mae: 0.0245 - val_loss: 0.0174 - val_mae: 0.0256\n",
      "Epoch 263/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.0017 - mae: 0.0240 - val_loss: 0.0176 - val_mae: 0.0254\n",
      "Epoch 264/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.0016 - mae: 0.0235 - val_loss: 0.0163 - val_mae: 0.0251\n",
      "Epoch 265/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.0016 - mae: 0.0238 - val_loss: 0.0153 - val_mae: 0.0250\n",
      "Epoch 266/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.0017 - mae: 0.0236 - val_loss: 0.0175 - val_mae: 0.0252\n",
      "Epoch 267/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.0015 - mae: 0.0228 - val_loss: 0.0173 - val_mae: 0.0254\n",
      "Epoch 268/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.0015 - mae: 0.0232 - val_loss: 0.0151 - val_mae: 0.0253\n",
      "Epoch 269/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.0014 - mae: 0.0225 - val_loss: 0.0152 - val_mae: 0.0254\n",
      "Epoch 270/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.0015 - mae: 0.0225 - val_loss: 0.0159 - val_mae: 0.0252\n",
      "Epoch 271/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.0014 - mae: 0.0223 - val_loss: 0.0177 - val_mae: 0.0252\n",
      "Epoch 272/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.0014 - mae: 0.0221 - val_loss: 0.0142 - val_mae: 0.0248\n",
      "Epoch 273/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.0015 - mae: 0.0221 - val_loss: 0.0119 - val_mae: 0.0250\n",
      "Epoch 274/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.0014 - mae: 0.0217 - val_loss: 0.0150 - val_mae: 0.0251\n",
      "Epoch 275/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.0013 - mae: 0.0215 - val_loss: 0.0168 - val_mae: 0.0252\n",
      "Epoch 276/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.0014 - mae: 0.0216 - val_loss: 0.0153 - val_mae: 0.0247\n",
      "Epoch 277/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.0013 - mae: 0.0214 - val_loss: 0.0135 - val_mae: 0.0247\n",
      "Epoch 278/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.0012 - mae: 0.0208 - val_loss: 0.0126 - val_mae: 0.0245\n",
      "Epoch 279/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.0014 - mae: 0.0214 - val_loss: 0.0114 - val_mae: 0.0243\n",
      "Epoch 280/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.0012 - mae: 0.0208 - val_loss: 0.0148 - val_mae: 0.0244\n",
      "Epoch 281/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.0012 - mae: 0.0205 - val_loss: 0.0151 - val_mae: 0.0247\n",
      "Epoch 282/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.0011 - mae: 0.0200 - val_loss: 0.0129 - val_mae: 0.0245\n",
      "Epoch 283/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.0012 - mae: 0.0206 - val_loss: 0.0134 - val_mae: 0.0243\n",
      "Epoch 284/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.0012 - mae: 0.0203 - val_loss: 0.0116 - val_mae: 0.0247\n",
      "Epoch 285/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.0011 - mae: 0.0203 - val_loss: 0.0161 - val_mae: 0.0247\n",
      "Epoch 286/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.0012 - mae: 0.0201 - val_loss: 0.0118 - val_mae: 0.0242\n",
      "Epoch 287/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.0011 - mae: 0.0198 - val_loss: 0.0121 - val_mae: 0.0243\n",
      "Epoch 288/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.0012 - mae: 0.0199 - val_loss: 0.0127 - val_mae: 0.0243\n",
      "Epoch 289/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.0011 - mae: 0.0196 - val_loss: 0.0161 - val_mae: 0.0244\n",
      "Epoch 290/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.0011 - mae: 0.0196 - val_loss: 0.0106 - val_mae: 0.0239\n",
      "Epoch 291/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.0011 - mae: 0.0197 - val_loss: 0.0103 - val_mae: 0.0240\n",
      "Epoch 292/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.0010 - mae: 0.0194 - val_loss: 0.0104 - val_mae: 0.0238\n",
      "Epoch 293/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.0013 - mae: 0.0197 - val_loss: 0.0119 - val_mae: 0.0242\n",
      "Epoch 294/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 9.9074e-04 - mae: 0.0190 - val_loss: 0.0114 - val_mae: 0.0240\n",
      "Epoch 295/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.0012 - mae: 0.0193 - val_loss: 0.0092 - val_mae: 0.0239\n",
      "Epoch 296/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.0011 - mae: 0.0191 - val_loss: 0.0096 - val_mae: 0.0237\n",
      "Epoch 297/5000\n",
      "57/57 [==============================] - 1s 12ms/step - loss: 0.0011 - mae: 0.0193 - val_loss: 0.0122 - val_mae: 0.0239\n",
      "Epoch 298/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 9.8173e-04 - mae: 0.0188 - val_loss: 0.0087 - val_mae: 0.0235\n",
      "Epoch 299/5000\n",
      "57/57 [==============================] - 1s 12ms/step - loss: 0.0011 - mae: 0.0190 - val_loss: 0.0090 - val_mae: 0.0237\n",
      "Epoch 300/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.0010 - mae: 0.0188 - val_loss: 0.0120 - val_mae: 0.0239\n",
      "Epoch 301/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 9.9980e-04 - mae: 0.0186 - val_loss: 0.0078 - val_mae: 0.0235\n",
      "Epoch 302/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.0011 - mae: 0.0191 - val_loss: 0.0056 - val_mae: 0.0232\n",
      "Epoch 303/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.0011 - mae: 0.0188 - val_loss: 0.0103 - val_mae: 0.0239\n",
      "Epoch 304/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.0011 - mae: 0.0190 - val_loss: 0.0094 - val_mae: 0.0236\n",
      "Epoch 305/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 9.8882e-04 - mae: 0.0184 - val_loss: 0.0111 - val_mae: 0.0236\n",
      "Epoch 306/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 9.8384e-04 - mae: 0.0184 - val_loss: 0.0133 - val_mae: 0.0238\n",
      "Epoch 307/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.0010 - mae: 0.0186 - val_loss: 0.0110 - val_mae: 0.0236\n",
      "Epoch 308/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 9.3264e-04 - mae: 0.0181 - val_loss: 0.0108 - val_mae: 0.0237\n",
      "Epoch 309/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 9.6034e-04 - mae: 0.0179 - val_loss: 0.0085 - val_mae: 0.0235\n",
      "Epoch 310/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.0010 - mae: 0.0185 - val_loss: 0.0090 - val_mae: 0.0236\n",
      "Epoch 311/5000\n",
      "57/57 [==============================] - 1s 12ms/step - loss: 8.9186e-04 - mae: 0.0180 - val_loss: 0.0088 - val_mae: 0.0233\n",
      "Epoch 312/5000\n",
      "57/57 [==============================] - 1s 12ms/step - loss: 9.5419e-04 - mae: 0.0180 - val_loss: 0.0098 - val_mae: 0.0235\n",
      "Epoch 313/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 9.3906e-04 - mae: 0.0178 - val_loss: 0.0126 - val_mae: 0.0238\n",
      "Epoch 314/5000\n",
      "57/57 [==============================] - 1s 12ms/step - loss: 0.0010 - mae: 0.0183 - val_loss: 0.0106 - val_mae: 0.0235\n",
      "Epoch 315/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 8.8413e-04 - mae: 0.0176 - val_loss: 0.0120 - val_mae: 0.0236\n",
      "Epoch 316/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 9.8255e-04 - mae: 0.0179 - val_loss: 0.0087 - val_mae: 0.0234\n",
      "Epoch 317/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 9.0310e-04 - mae: 0.0177 - val_loss: 0.0076 - val_mae: 0.0231\n",
      "Epoch 318/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 9.5005e-04 - mae: 0.0179 - val_loss: 0.0096 - val_mae: 0.0234\n",
      "Epoch 319/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 8.2216e-04 - mae: 0.0174 - val_loss: 0.0104 - val_mae: 0.0233\n",
      "Epoch 320/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 8.7616e-04 - mae: 0.0176 - val_loss: 0.0102 - val_mae: 0.0232\n",
      "Epoch 321/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 8.2549e-04 - mae: 0.0171 - val_loss: 0.0080 - val_mae: 0.0229\n",
      "Epoch 322/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 8.8160e-04 - mae: 0.0173 - val_loss: 0.0094 - val_mae: 0.0231\n",
      "Epoch 323/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 8.7304e-04 - mae: 0.0174 - val_loss: 0.0096 - val_mae: 0.0230\n",
      "Epoch 324/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 8.5642e-04 - mae: 0.0173 - val_loss: 0.0087 - val_mae: 0.0229\n",
      "Epoch 325/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 8.3063e-04 - mae: 0.0174 - val_loss: 0.0083 - val_mae: 0.0227\n",
      "Epoch 326/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 8.3297e-04 - mae: 0.0172 - val_loss: 0.0082 - val_mae: 0.0228\n",
      "Epoch 327/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 8.4116e-04 - mae: 0.0172 - val_loss: 0.0092 - val_mae: 0.0228\n",
      "Epoch 328/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 9.1878e-04 - mae: 0.0176 - val_loss: 0.0066 - val_mae: 0.0226\n",
      "Epoch 329/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 8.2588e-04 - mae: 0.0172 - val_loss: 0.0075 - val_mae: 0.0229\n",
      "Epoch 330/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 8.7502e-04 - mae: 0.0169 - val_loss: 0.0082 - val_mae: 0.0229\n",
      "Epoch 331/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 8.0292e-04 - mae: 0.0169 - val_loss: 0.0087 - val_mae: 0.0229\n",
      "Epoch 332/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 8.2449e-04 - mae: 0.0169 - val_loss: 0.0095 - val_mae: 0.0228\n",
      "Epoch 333/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 8.9124e-04 - mae: 0.0171 - val_loss: 0.0081 - val_mae: 0.0227\n",
      "Epoch 334/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 8.6821e-04 - mae: 0.0173 - val_loss: 0.0063 - val_mae: 0.0226\n",
      "Epoch 335/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 8.1088e-04 - mae: 0.0167 - val_loss: 0.0086 - val_mae: 0.0228\n",
      "Epoch 336/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 8.1401e-04 - mae: 0.0169 - val_loss: 0.0095 - val_mae: 0.0229\n",
      "Epoch 337/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 9.1784e-04 - mae: 0.0171 - val_loss: 0.0067 - val_mae: 0.0226\n",
      "Epoch 338/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 7.9971e-04 - mae: 0.0165 - val_loss: 0.0080 - val_mae: 0.0228\n",
      "Epoch 339/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 7.7365e-04 - mae: 0.0166 - val_loss: 0.0076 - val_mae: 0.0227\n",
      "Epoch 340/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 7.3811e-04 - mae: 0.0164 - val_loss: 0.0085 - val_mae: 0.0229\n",
      "Epoch 341/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 8.1391e-04 - mae: 0.0165 - val_loss: 0.0077 - val_mae: 0.0228\n",
      "Epoch 342/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 6.9070e-04 - mae: 0.0161 - val_loss: 0.0093 - val_mae: 0.0229\n",
      "Epoch 343/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 8.1055e-04 - mae: 0.0166 - val_loss: 0.0079 - val_mae: 0.0228\n",
      "Epoch 344/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 8.0386e-04 - mae: 0.0165 - val_loss: 0.0059 - val_mae: 0.0225\n",
      "Epoch 345/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 8.3333e-04 - mae: 0.0167 - val_loss: 0.0071 - val_mae: 0.0226\n",
      "Epoch 346/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 8.1633e-04 - mae: 0.0162 - val_loss: 0.0065 - val_mae: 0.0226\n",
      "Epoch 347/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 7.8337e-04 - mae: 0.0161 - val_loss: 0.0087 - val_mae: 0.0230\n",
      "Epoch 348/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 8.4873e-04 - mae: 0.0166 - val_loss: 0.0090 - val_mae: 0.0228\n",
      "Epoch 349/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 7.4022e-04 - mae: 0.0160 - val_loss: 0.0051 - val_mae: 0.0223\n",
      "Epoch 350/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 8.0959e-04 - mae: 0.0162 - val_loss: 0.0089 - val_mae: 0.0225\n",
      "Epoch 351/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 7.6507e-04 - mae: 0.0163 - val_loss: 0.0078 - val_mae: 0.0225\n",
      "Epoch 352/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 7.7227e-04 - mae: 0.0163 - val_loss: 0.0064 - val_mae: 0.0224\n",
      "Epoch 353/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 8.5698e-04 - mae: 0.0163 - val_loss: 0.0086 - val_mae: 0.0227\n",
      "Epoch 354/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 7.4398e-04 - mae: 0.0162 - val_loss: 0.0072 - val_mae: 0.0225\n",
      "Epoch 355/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 7.6890e-04 - mae: 0.0161 - val_loss: 0.0102 - val_mae: 0.0228\n",
      "Epoch 356/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 7.1546e-04 - mae: 0.0160 - val_loss: 0.0090 - val_mae: 0.0226\n",
      "Epoch 357/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 7.7996e-04 - mae: 0.0159 - val_loss: 0.0098 - val_mae: 0.0226\n",
      "Epoch 358/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 8.8197e-04 - mae: 0.0165 - val_loss: 0.0077 - val_mae: 0.0226\n",
      "Epoch 359/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 7.7650e-04 - mae: 0.0161 - val_loss: 0.0074 - val_mae: 0.0224\n",
      "Epoch 360/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 7.3699e-04 - mae: 0.0159 - val_loss: 0.0078 - val_mae: 0.0225\n",
      "Epoch 361/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 6.6832e-04 - mae: 0.0152 - val_loss: 0.0080 - val_mae: 0.0226\n",
      "Epoch 362/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 7.2823e-04 - mae: 0.0156 - val_loss: 0.0082 - val_mae: 0.0225\n",
      "Epoch 363/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 7.2176e-04 - mae: 0.0159 - val_loss: 0.0067 - val_mae: 0.0222\n",
      "Epoch 364/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 6.9554e-04 - mae: 0.0155 - val_loss: 0.0083 - val_mae: 0.0224\n",
      "Epoch 365/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 7.2882e-04 - mae: 0.0157 - val_loss: 0.0059 - val_mae: 0.0223\n",
      "Epoch 366/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 7.5427e-04 - mae: 0.0158 - val_loss: 0.0073 - val_mae: 0.0223\n",
      "Epoch 367/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 6.9683e-04 - mae: 0.0154 - val_loss: 0.0074 - val_mae: 0.0223\n",
      "Epoch 368/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 6.6052e-04 - mae: 0.0155 - val_loss: 0.0063 - val_mae: 0.0222\n",
      "Epoch 369/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 7.2039e-04 - mae: 0.0158 - val_loss: 0.0068 - val_mae: 0.0223\n",
      "Epoch 370/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 6.6902e-04 - mae: 0.0151 - val_loss: 0.0054 - val_mae: 0.0222\n",
      "Epoch 371/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 7.1704e-04 - mae: 0.0156 - val_loss: 0.0093 - val_mae: 0.0226\n",
      "Epoch 372/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 7.0111e-04 - mae: 0.0156 - val_loss: 0.0072 - val_mae: 0.0223\n",
      "Epoch 373/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 6.8983e-04 - mae: 0.0155 - val_loss: 0.0069 - val_mae: 0.0223\n",
      "Epoch 374/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 7.1249e-04 - mae: 0.0155 - val_loss: 0.0074 - val_mae: 0.0223\n",
      "Epoch 375/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 7.0726e-04 - mae: 0.0155 - val_loss: 0.0072 - val_mae: 0.0224\n",
      "Epoch 376/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 7.8420e-04 - mae: 0.0156 - val_loss: 0.0108 - val_mae: 0.0228\n",
      "Epoch 377/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 8.6281e-04 - mae: 0.0157 - val_loss: 0.0056 - val_mae: 0.0225\n",
      "Epoch 378/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 6.9780e-04 - mae: 0.0153 - val_loss: 0.0072 - val_mae: 0.0225\n",
      "Epoch 379/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 7.5644e-04 - mae: 0.0153 - val_loss: 0.0095 - val_mae: 0.0229\n",
      "Epoch 380/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 7.3803e-04 - mae: 0.0155 - val_loss: 0.0057 - val_mae: 0.0224\n",
      "Epoch 381/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 6.9247e-04 - mae: 0.0152 - val_loss: 0.0077 - val_mae: 0.0225\n",
      "Epoch 382/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 7.0126e-04 - mae: 0.0152 - val_loss: 0.0069 - val_mae: 0.0225\n",
      "Epoch 383/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 6.7167e-04 - mae: 0.0147 - val_loss: 0.0066 - val_mae: 0.0223\n",
      "Epoch 384/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 6.5372e-04 - mae: 0.0148 - val_loss: 0.0072 - val_mae: 0.0224\n",
      "Epoch 385/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 7.1979e-04 - mae: 0.0152 - val_loss: 0.0069 - val_mae: 0.0222\n",
      "Epoch 386/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 6.1422e-04 - mae: 0.0150 - val_loss: 0.0058 - val_mae: 0.0222\n",
      "Epoch 387/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 7.1285e-04 - mae: 0.0153 - val_loss: 0.0067 - val_mae: 0.0223\n",
      "Epoch 388/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 6.4400e-04 - mae: 0.0150 - val_loss: 0.0080 - val_mae: 0.0225\n",
      "Epoch 389/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 7.0732e-04 - mae: 0.0151 - val_loss: 0.0047 - val_mae: 0.0222\n",
      "Epoch 390/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 6.8756e-04 - mae: 0.0151 - val_loss: 0.0045 - val_mae: 0.0221\n",
      "Epoch 391/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 6.7851e-04 - mae: 0.0149 - val_loss: 0.0049 - val_mae: 0.0224\n",
      "Epoch 392/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 6.4866e-04 - mae: 0.0150 - val_loss: 0.0043 - val_mae: 0.0220\n",
      "Epoch 393/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 6.9327e-04 - mae: 0.0150 - val_loss: 0.0052 - val_mae: 0.0222\n",
      "Epoch 394/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 6.7457e-04 - mae: 0.0151 - val_loss: 0.0060 - val_mae: 0.0222\n",
      "Epoch 395/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 6.9692e-04 - mae: 0.0150 - val_loss: 0.0063 - val_mae: 0.0224\n",
      "Epoch 396/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 7.0848e-04 - mae: 0.0152 - val_loss: 0.0056 - val_mae: 0.0222\n",
      "Epoch 397/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 5.8511e-04 - mae: 0.0145 - val_loss: 0.0063 - val_mae: 0.0223\n",
      "Epoch 398/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 6.5872e-04 - mae: 0.0147 - val_loss: 0.0053 - val_mae: 0.0221\n",
      "Epoch 399/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 6.6595e-04 - mae: 0.0146 - val_loss: 0.0079 - val_mae: 0.0225\n",
      "Epoch 400/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 6.2450e-04 - mae: 0.0147 - val_loss: 0.0082 - val_mae: 0.0224\n",
      "Epoch 401/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 6.7071e-04 - mae: 0.0150 - val_loss: 0.0068 - val_mae: 0.0224\n",
      "Epoch 402/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 6.3609e-04 - mae: 0.0144 - val_loss: 0.0068 - val_mae: 0.0224\n",
      "Epoch 403/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 6.1736e-04 - mae: 0.0141 - val_loss: 0.0073 - val_mae: 0.0223\n",
      "Epoch 404/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 6.8926e-04 - mae: 0.0148 - val_loss: 0.0092 - val_mae: 0.0226\n",
      "Epoch 405/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 6.2583e-04 - mae: 0.0142 - val_loss: 0.0074 - val_mae: 0.0225\n",
      "Epoch 406/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 6.4110e-04 - mae: 0.0149 - val_loss: 0.0061 - val_mae: 0.0223\n",
      "Epoch 407/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 6.4378e-04 - mae: 0.0146 - val_loss: 0.0043 - val_mae: 0.0222\n",
      "Epoch 408/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 6.6111e-04 - mae: 0.0144 - val_loss: 0.0074 - val_mae: 0.0225\n",
      "Epoch 409/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 5.8653e-04 - mae: 0.0144 - val_loss: 0.0068 - val_mae: 0.0224\n",
      "Epoch 410/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 6.9214e-04 - mae: 0.0147 - val_loss: 0.0063 - val_mae: 0.0223\n",
      "Epoch 411/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 6.2541e-04 - mae: 0.0144 - val_loss: 0.0056 - val_mae: 0.0224\n",
      "Epoch 412/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 6.6463e-04 - mae: 0.0146 - val_loss: 0.0060 - val_mae: 0.0224\n",
      "Epoch 413/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 6.3186e-04 - mae: 0.0144 - val_loss: 0.0066 - val_mae: 0.0224\n",
      "Epoch 414/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 6.5736e-04 - mae: 0.0142 - val_loss: 0.0063 - val_mae: 0.0223\n",
      "Epoch 415/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 5.8490e-04 - mae: 0.0139 - val_loss: 0.0060 - val_mae: 0.0223\n",
      "Epoch 416/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 6.4291e-04 - mae: 0.0144 - val_loss: 0.0054 - val_mae: 0.0224\n",
      "Epoch 417/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 6.7219e-04 - mae: 0.0142 - val_loss: 0.0056 - val_mae: 0.0224\n",
      "Epoch 418/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 6.2782e-04 - mae: 0.0144 - val_loss: 0.0068 - val_mae: 0.0225\n",
      "Epoch 419/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 5.9508e-04 - mae: 0.0144 - val_loss: 0.0048 - val_mae: 0.0223\n",
      "Epoch 420/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 6.0973e-04 - mae: 0.0140 - val_loss: 0.0076 - val_mae: 0.0226\n",
      "Epoch 421/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 6.2439e-04 - mae: 0.0144 - val_loss: 0.0058 - val_mae: 0.0224\n",
      "Epoch 422/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 6.1688e-04 - mae: 0.0142 - val_loss: 0.0063 - val_mae: 0.0223\n",
      "Epoch 423/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 6.6224e-04 - mae: 0.0146 - val_loss: 0.0060 - val_mae: 0.0223\n",
      "Epoch 424/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 6.2880e-04 - mae: 0.0143 - val_loss: 0.0047 - val_mae: 0.0222\n",
      "Epoch 425/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 6.8854e-04 - mae: 0.0146 - val_loss: 0.0076 - val_mae: 0.0225\n",
      "Epoch 426/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 5.9850e-04 - mae: 0.0143 - val_loss: 0.0046 - val_mae: 0.0223\n",
      "Epoch 427/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 5.9702e-04 - mae: 0.0140 - val_loss: 0.0064 - val_mae: 0.0225\n",
      "Epoch 428/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 6.0128e-04 - mae: 0.0141 - val_loss: 0.0065 - val_mae: 0.0224\n",
      "Epoch 429/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 5.8933e-04 - mae: 0.0143 - val_loss: 0.0062 - val_mae: 0.0223\n",
      "Epoch 430/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 6.4714e-04 - mae: 0.0143 - val_loss: 0.0083 - val_mae: 0.0227\n",
      "Epoch 431/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 6.6662e-04 - mae: 0.0142 - val_loss: 0.0066 - val_mae: 0.0224\n",
      "Epoch 432/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 6.2546e-04 - mae: 0.0143 - val_loss: 0.0082 - val_mae: 0.0226\n",
      "Epoch 433/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 6.2591e-04 - mae: 0.0143 - val_loss: 0.0063 - val_mae: 0.0224\n",
      "Epoch 434/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 5.8536e-04 - mae: 0.0142 - val_loss: 0.0069 - val_mae: 0.0225\n",
      "Epoch 435/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 5.4701e-04 - mae: 0.0136 - val_loss: 0.0064 - val_mae: 0.0225\n",
      "Epoch 436/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 6.0493e-04 - mae: 0.0140 - val_loss: 0.0089 - val_mae: 0.0226\n",
      "Epoch 437/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 6.7157e-04 - mae: 0.0139 - val_loss: 0.0088 - val_mae: 0.0227\n",
      "Epoch 438/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 6.5170e-04 - mae: 0.0140 - val_loss: 0.0059 - val_mae: 0.0224\n",
      "Epoch 439/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 6.2618e-04 - mae: 0.0140 - val_loss: 0.0071 - val_mae: 0.0225\n",
      "Epoch 440/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 6.1623e-04 - mae: 0.0143 - val_loss: 0.0053 - val_mae: 0.0223\n",
      "Epoch 441/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 6.1477e-04 - mae: 0.0143 - val_loss: 0.0064 - val_mae: 0.0223\n",
      "Epoch 442/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 5.9128e-04 - mae: 0.0141 - val_loss: 0.0061 - val_mae: 0.0223\n",
      "Epoch 443/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 6.1247e-04 - mae: 0.0142 - val_loss: 0.0079 - val_mae: 0.0225\n",
      "Epoch 444/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 6.2506e-04 - mae: 0.0139 - val_loss: 0.0039 - val_mae: 0.0222\n",
      "Epoch 445/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 6.0936e-04 - mae: 0.0143 - val_loss: 0.0070 - val_mae: 0.0226\n",
      "Epoch 446/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 5.7153e-04 - mae: 0.0138 - val_loss: 0.0066 - val_mae: 0.0224\n",
      "Epoch 447/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 6.4011e-04 - mae: 0.0139 - val_loss: 0.0052 - val_mae: 0.0224\n",
      "Epoch 448/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 5.6236e-04 - mae: 0.0138 - val_loss: 0.0056 - val_mae: 0.0225\n",
      "Epoch 449/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 6.0510e-04 - mae: 0.0142 - val_loss: 0.0061 - val_mae: 0.0225\n",
      "Epoch 450/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 6.2038e-04 - mae: 0.0140 - val_loss: 0.0056 - val_mae: 0.0225\n",
      "Epoch 451/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 6.5723e-04 - mae: 0.0139 - val_loss: 0.0068 - val_mae: 0.0226\n",
      "Epoch 452/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 6.0237e-04 - mae: 0.0137 - val_loss: 0.0054 - val_mae: 0.0224\n",
      "Epoch 453/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 6.3972e-04 - mae: 0.0141 - val_loss: 0.0069 - val_mae: 0.0226\n",
      "Epoch 454/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 6.3383e-04 - mae: 0.0143 - val_loss: 0.0059 - val_mae: 0.0224\n",
      "Epoch 455/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 6.1388e-04 - mae: 0.0137 - val_loss: 0.0053 - val_mae: 0.0224\n",
      "Epoch 456/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 5.9120e-04 - mae: 0.0137 - val_loss: 0.0049 - val_mae: 0.0223\n",
      "Epoch 457/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 5.9255e-04 - mae: 0.0140 - val_loss: 0.0064 - val_mae: 0.0225\n",
      "Epoch 458/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 6.3141e-04 - mae: 0.0139 - val_loss: 0.0061 - val_mae: 0.0225\n",
      "Epoch 459/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 5.6866e-04 - mae: 0.0137 - val_loss: 0.0060 - val_mae: 0.0226\n",
      "Epoch 460/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 7.1206e-04 - mae: 0.0142 - val_loss: 0.0069 - val_mae: 0.0227\n",
      "Epoch 461/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 5.7073e-04 - mae: 0.0139 - val_loss: 0.0076 - val_mae: 0.0225\n",
      "Epoch 462/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 5.8665e-04 - mae: 0.0140 - val_loss: 0.0069 - val_mae: 0.0225\n",
      "Epoch 463/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 5.8211e-04 - mae: 0.0140 - val_loss: 0.0062 - val_mae: 0.0224\n",
      "Epoch 464/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 5.8880e-04 - mae: 0.0140 - val_loss: 0.0077 - val_mae: 0.0226\n",
      "Epoch 465/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 6.4636e-04 - mae: 0.0141 - val_loss: 0.0073 - val_mae: 0.0226\n",
      "Epoch 466/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 6.4203e-04 - mae: 0.0139 - val_loss: 0.0057 - val_mae: 0.0224\n",
      "Epoch 467/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 5.7832e-04 - mae: 0.0137 - val_loss: 0.0054 - val_mae: 0.0223\n",
      "Epoch 468/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 6.3143e-04 - mae: 0.0136 - val_loss: 0.0055 - val_mae: 0.0225\n",
      "Epoch 469/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 6.0973e-04 - mae: 0.0140 - val_loss: 0.0059 - val_mae: 0.0224\n",
      "Epoch 470/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 6.3532e-04 - mae: 0.0140 - val_loss: 0.0065 - val_mae: 0.0226\n",
      "Epoch 471/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 5.8865e-04 - mae: 0.0137 - val_loss: 0.0061 - val_mae: 0.0226\n",
      "Epoch 472/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 5.3925e-04 - mae: 0.0136 - val_loss: 0.0062 - val_mae: 0.0224\n",
      "Epoch 473/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 6.1470e-04 - mae: 0.0139 - val_loss: 0.0057 - val_mae: 0.0225\n",
      "Epoch 474/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 5.6741e-04 - mae: 0.0135 - val_loss: 0.0080 - val_mae: 0.0227\n",
      "Epoch 475/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 6.3909e-04 - mae: 0.0137 - val_loss: 0.0092 - val_mae: 0.0227\n",
      "Epoch 476/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 7.0349e-04 - mae: 0.0139 - val_loss: 0.0059 - val_mae: 0.0226\n",
      "Epoch 477/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 5.8248e-04 - mae: 0.0138 - val_loss: 0.0047 - val_mae: 0.0225\n",
      "Epoch 478/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 6.2117e-04 - mae: 0.0140 - val_loss: 0.0072 - val_mae: 0.0226\n",
      "Epoch 479/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 5.8032e-04 - mae: 0.0135 - val_loss: 0.0078 - val_mae: 0.0227\n",
      "Epoch 480/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 5.5887e-04 - mae: 0.0139 - val_loss: 0.0076 - val_mae: 0.0226\n",
      "Epoch 481/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 6.3320e-04 - mae: 0.0139 - val_loss: 0.0065 - val_mae: 0.0225\n",
      "Epoch 482/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 5.7292e-04 - mae: 0.0137 - val_loss: 0.0055 - val_mae: 0.0225\n",
      "Epoch 483/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 5.8251e-04 - mae: 0.0133 - val_loss: 0.0066 - val_mae: 0.0226\n",
      "Epoch 484/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 5.5976e-04 - mae: 0.0137 - val_loss: 0.0063 - val_mae: 0.0225\n",
      "Epoch 485/5000\n",
      "57/57 [==============================] - 1s 12ms/step - loss: 5.3354e-04 - mae: 0.0133 - val_loss: 0.0065 - val_mae: 0.0227\n",
      "Epoch 486/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 6.1312e-04 - mae: 0.0137 - val_loss: 0.0070 - val_mae: 0.0225\n",
      "Epoch 487/5000\n",
      "57/57 [==============================] - 1s 12ms/step - loss: 6.0520e-04 - mae: 0.0138 - val_loss: 0.0072 - val_mae: 0.0226\n",
      "Epoch 488/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 5.7303e-04 - mae: 0.0136 - val_loss: 0.0072 - val_mae: 0.0226\n",
      "Epoch 489/5000\n",
      "57/57 [==============================] - 1s 12ms/step - loss: 5.8005e-04 - mae: 0.0136 - val_loss: 0.0058 - val_mae: 0.0224\n",
      "Epoch 490/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 5.2266e-04 - mae: 0.0133 - val_loss: 0.0064 - val_mae: 0.0224\n",
      "Epoch 491/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 5.6055e-04 - mae: 0.0134 - val_loss: 0.0060 - val_mae: 0.0224\n",
      "Epoch 492/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 5.3386e-04 - mae: 0.0130 - val_loss: 0.0055 - val_mae: 0.0224\n",
      "Epoch 493/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 5.6126e-04 - mae: 0.0132 - val_loss: 0.0077 - val_mae: 0.0225\n",
      "Epoch 494/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 6.0151e-04 - mae: 0.0137 - val_loss: 0.0058 - val_mae: 0.0225\n",
      "Epoch 495/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 5.3174e-04 - mae: 0.0132 - val_loss: 0.0078 - val_mae: 0.0226\n",
      "Epoch 496/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 6.6168e-04 - mae: 0.0137 - val_loss: 0.0074 - val_mae: 0.0225\n",
      "Epoch 497/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 5.2851e-04 - mae: 0.0133 - val_loss: 0.0072 - val_mae: 0.0225\n",
      "Epoch 498/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 5.3245e-04 - mae: 0.0133 - val_loss: 0.0066 - val_mae: 0.0224\n",
      "Epoch 499/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 5.2585e-04 - mae: 0.0134 - val_loss: 0.0068 - val_mae: 0.0224\n",
      "Epoch 500/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 5.5278e-04 - mae: 0.0132 - val_loss: 0.0063 - val_mae: 0.0225\n",
      "Epoch 501/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 5.7022e-04 - mae: 0.0135 - val_loss: 0.0057 - val_mae: 0.0224\n",
      "Epoch 502/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 5.7866e-04 - mae: 0.0134 - val_loss: 0.0069 - val_mae: 0.0225\n",
      "Epoch 503/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 5.8300e-04 - mae: 0.0136 - val_loss: 0.0067 - val_mae: 0.0226\n",
      "Epoch 504/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 5.6004e-04 - mae: 0.0135 - val_loss: 0.0056 - val_mae: 0.0224\n",
      "Epoch 505/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 5.5827e-04 - mae: 0.0132 - val_loss: 0.0063 - val_mae: 0.0224\n",
      "Epoch 506/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 5.8261e-04 - mae: 0.0135 - val_loss: 0.0070 - val_mae: 0.0226\n",
      "Epoch 507/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 5.8407e-04 - mae: 0.0135 - val_loss: 0.0068 - val_mae: 0.0225\n",
      "Epoch 508/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 6.1048e-04 - mae: 0.0135 - val_loss: 0.0056 - val_mae: 0.0226\n",
      "Epoch 509/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 5.5792e-04 - mae: 0.0134 - val_loss: 0.0069 - val_mae: 0.0228\n",
      "Epoch 510/5000\n",
      "57/57 [==============================] - 1s 12ms/step - loss: 5.1884e-04 - mae: 0.0133 - val_loss: 0.0058 - val_mae: 0.0225\n",
      "Epoch 511/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 5.1803e-04 - mae: 0.0132 - val_loss: 0.0056 - val_mae: 0.0224\n",
      "Epoch 512/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 5.9165e-04 - mae: 0.0135 - val_loss: 0.0073 - val_mae: 0.0227\n",
      "Epoch 513/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 6.5632e-04 - mae: 0.0136 - val_loss: 0.0107 - val_mae: 0.0228\n",
      "Epoch 514/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 6.8827e-04 - mae: 0.0136 - val_loss: 0.0067 - val_mae: 0.0228\n",
      "Epoch 515/5000\n",
      "57/57 [==============================] - 1s 12ms/step - loss: 6.0058e-04 - mae: 0.0134 - val_loss: 0.0058 - val_mae: 0.0226\n",
      "Epoch 516/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 5.4805e-04 - mae: 0.0132 - val_loss: 0.0070 - val_mae: 0.0225\n",
      "Epoch 517/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 5.6065e-04 - mae: 0.0134 - val_loss: 0.0074 - val_mae: 0.0224\n",
      "Epoch 518/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 5.5351e-04 - mae: 0.0136 - val_loss: 0.0070 - val_mae: 0.0225\n",
      "Epoch 519/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 5.3421e-04 - mae: 0.0131 - val_loss: 0.0063 - val_mae: 0.0225\n",
      "Epoch 520/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 6.9795e-04 - mae: 0.0136 - val_loss: 0.0072 - val_mae: 0.0227\n",
      "Epoch 521/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 5.2410e-04 - mae: 0.0134 - val_loss: 0.0065 - val_mae: 0.0224\n",
      "Epoch 522/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 5.7773e-04 - mae: 0.0136 - val_loss: 0.0075 - val_mae: 0.0225\n",
      "Epoch 523/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 5.7162e-04 - mae: 0.0136 - val_loss: 0.0063 - val_mae: 0.0224\n",
      "Epoch 524/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 5.3905e-04 - mae: 0.0130 - val_loss: 0.0068 - val_mae: 0.0225\n",
      "Epoch 525/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 5.8599e-04 - mae: 0.0132 - val_loss: 0.0055 - val_mae: 0.0224\n",
      "Epoch 526/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 5.5986e-04 - mae: 0.0133 - val_loss: 0.0061 - val_mae: 0.0224\n",
      "Epoch 527/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 5.7666e-04 - mae: 0.0133 - val_loss: 0.0064 - val_mae: 0.0223\n",
      "Epoch 528/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 5.1279e-04 - mae: 0.0131 - val_loss: 0.0069 - val_mae: 0.0224\n",
      "Epoch 529/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 5.7245e-04 - mae: 0.0132 - val_loss: 0.0051 - val_mae: 0.0223\n",
      "Epoch 530/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 5.8687e-04 - mae: 0.0134 - val_loss: 0.0052 - val_mae: 0.0224\n",
      "Epoch 531/5000\n",
      "57/57 [==============================] - 1s 12ms/step - loss: 5.9218e-04 - mae: 0.0134 - val_loss: 0.0057 - val_mae: 0.0224\n",
      "Epoch 532/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 6.0300e-04 - mae: 0.0133 - val_loss: 0.0048 - val_mae: 0.0226\n",
      "Epoch 533/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 5.5577e-04 - mae: 0.0132 - val_loss: 0.0070 - val_mae: 0.0226\n",
      "Epoch 534/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 5.7136e-04 - mae: 0.0134 - val_loss: 0.0052 - val_mae: 0.0226\n",
      "Epoch 535/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 5.4024e-04 - mae: 0.0131 - val_loss: 0.0059 - val_mae: 0.0224\n",
      "Epoch 536/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 4.9129e-04 - mae: 0.0127 - val_loss: 0.0081 - val_mae: 0.0225\n",
      "Epoch 537/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 5.3365e-04 - mae: 0.0129 - val_loss: 0.0061 - val_mae: 0.0224\n",
      "Epoch 538/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 5.5551e-04 - mae: 0.0135 - val_loss: 0.0070 - val_mae: 0.0224\n",
      "Epoch 539/5000\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 6.0179e-04 - mae: 0.0134 - val_loss: 0.0066 - val_mae: 0.0225\n",
      "Epoch 540/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 5.3182e-04 - mae: 0.0130 - val_loss: 0.0070 - val_mae: 0.0224\n",
      "Epoch 541/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 4.9850e-04 - mae: 0.0129 - val_loss: 0.0056 - val_mae: 0.0223\n",
      "Epoch 542/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 5.5988e-04 - mae: 0.0131 - val_loss: 0.0066 - val_mae: 0.0223\n",
      "Epoch 543/5000\n",
      "57/57 [==============================] - 1s 12ms/step - loss: 5.0015e-04 - mae: 0.0132 - val_loss: 0.0086 - val_mae: 0.0225\n",
      "Epoch 544/5000\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 5.0192e-04 - mae: 0.0127 - val_loss: 0.0070 - val_mae: 0.0224\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    x_train,y_train,\n",
    "    epochs=5000,\n",
    "    validation_data=(x_val,y_val),\n",
    "    batch_size=256,   \n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "46953af7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "#loss\n",
    "plt.plot(epochs,loss,\"g\",label=\"Training loss\")\n",
    "plt.plot(epochs,val_loss,\"purple\",label=\"Validation loss\")\n",
    "plt.xlabel=\"Epoch\"\n",
    "plt.ylabel=\"loss\"\n",
    "plt.title=\"Training and validation loss\"\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "449e3f9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97/97 [==============================] - 0s 4ms/step - loss: 161773.9219 - mae: 37.1802\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[161773.921875, 37.180213928222656]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#evaluation\n",
    "output_model_dir = os.path.join(cwd, 'output_model')\n",
    "model.save(output_model_dir + \"\\model_trained\" + \".h5\")\n",
    "model.evaluate(x_test, y_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb04a70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bbe13225",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 10, 11)\n",
      "1/1 [==============================] - 0s 16ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx= np.random.randint(0, len(x_test), 1)[0]\n",
    "x = x_test[idx]  # Use the first sample from the test set\n",
    "y = y_test[idx]  # Corresponding true labels\n",
    "x = np.expand_dims(x, axis=0)  # Add batch dimension\n",
    "print(x.shape)\n",
    "y_pred = model.predict(x)\n",
    "plt.plot(x[0, :, 0], x[0, :, 1], label='Input', color='orange')\n",
    "plt.plot(y[:, 0], y[:, 1], label='True', color='blue')\n",
    "plt.plot(y_pred[0, :, 0], y_pred[0, :, 1], label='Predicted', color='red')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3779d9ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
